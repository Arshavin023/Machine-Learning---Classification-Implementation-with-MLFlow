{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Hp\\\\Videos\\\\classification implementation - machine learning with MLFlow\\\\research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Hp\\\\Videos\\\\classification implementation - machine learning with MLFlow'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    train_data_path: Path\n",
    "    test_data_path: Path\n",
    "    model_name: str\n",
    "    learning_rate: float\n",
    "    n_estimators: int\n",
    "    max_depth: int\n",
    "    subsample: float\n",
    "    colsample_bytree: float\n",
    "    gamma: float\n",
    "    reg_alpha: float\n",
    "    reg_lambda: float\n",
    "    min_child_weight: int\n",
    "    eval_metric: str\n",
    "    early_stopping_rounds: int\n",
    "    tree_method: str\n",
    "    scale_pos_weight: int\n",
    "    objective: str\n",
    "    target_column: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-27 11:58:49,265: INFO: utils: NumExpr defaulting to 8 threads.]\n"
     ]
    }
   ],
   "source": [
    "## create configuration manager\n",
    "from mlProject.constants import *\n",
    "from mlProject.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "        params = self.params.XGBClassifier\n",
    "        schema = self.schema.TARGET_COLUMN\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            train_data_path=config.train_data_path,\n",
    "            test_data_path=config.test_data_path,\n",
    "            model_name=config.model_name,\n",
    "            learning_rate=params.learning_rate,\n",
    "            n_estimators=params.n_estimators,\n",
    "            max_depth=params.max_depth,\n",
    "            subsample=params.subsample,\n",
    "            colsample_bytree=params.colsample_bytree,\n",
    "            gamma=params.gamma,\n",
    "            reg_alpha=params.reg_alpha,\n",
    "            reg_lambda=params.reg_lambda,\n",
    "            min_child_weight=params.min_child_weight,\n",
    "            eval_metric=params.eval_metric,\n",
    "            early_stopping_rounds=params.early_stopping_rounds,\n",
    "            tree_method=params.tree_method,\n",
    "            scale_pos_weight = params.scale_pos_weight,\n",
    "            objective=params.objective,\n",
    "            target_column=schema.name\n",
    "        )\n",
    "\n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from mlProject import logger\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from mlProject.utils.common import feature_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self,config:ModelTrainerConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def train(self):\n",
    "        train_data = pd.read_csv(self.config.train_data_path)\n",
    "        test_data = pd.read_csv(self.config.test_data_path)\n",
    "\n",
    "        train_x = train_data.drop([self.config.target_column],axis=1)\n",
    "        test_x = test_data.drop([self.config.target_column],axis=1)\n",
    "        train_y = train_data[[self.config.target_column]]\n",
    "        test_y = test_data[[self.config.target_column]]\n",
    "\n",
    "        preprocessor = feature_processor()\n",
    "        # train_x_processed = preprocessor.fit_transform(train_x)\n",
    "        \n",
    "        xgb = XGBClassifier(learning_rate = self.config.learning_rate,\n",
    "                            n_estimators = self.config.n_estimators,\n",
    "                            max_depth = self.config.max_depth,\n",
    "                            subsample = self.config.subsample,\n",
    "                            colsample_bytree = self.config.colsample_bytree,\n",
    "                            gamma = self.config.gamma,\n",
    "                            reg_alpha = self.config.reg_alpha,\n",
    "                            reg_lambda = self.config.reg_lambda,\n",
    "                            min_child_weight = self.config.min_child_weight,\n",
    "                            eval_metric = self.config.eval_metric,\n",
    "                            #eval_stopping_rounds = self.config.early_stopping_rounds,\n",
    "                            tree_method = self.config.tree_method,\n",
    "                            scale_pos_weight = self.config.scale_pos_weight,\n",
    "                            objective = self.config.objective,\n",
    "                            random_state = 42)\n",
    "        \n",
    "        model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                         ('model', xgb)\n",
    "                                         ])\n",
    "\n",
    "        model_pipeline.fit(train_x,train_y)\n",
    "\n",
    "        joblib.dump(xgb,os.path.join(self.config.root_dir, self.config.model_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-27 11:59:08,424: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-09-27 11:59:08,434: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-09-27 11:59:08,439: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2023-09-27 11:59:08,439: INFO: common: created directory at: artifacts]\n",
      "[2023-09-27 11:59:08,444: INFO: common: created directory at: artifacts/model_trainer]\n"
     ]
    }
   ],
   "source": [
    "# testing the model trainer\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer = ModelTrainer(config=model_trainer_config)\n",
    "    model_trainer.train()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
